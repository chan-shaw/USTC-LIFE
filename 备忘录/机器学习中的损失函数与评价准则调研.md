

# 机器学习中的损失函数与评价准则调研

作者：肖郴，李生果，杨月麟

## 摘要

机器学习(Machine Learning, ML)是一门多领域交叉学科,涉及概率论、统计学、逼近论、凸分析、算法复杂度理论等多门学科。它是人工智能的核心,是使计算机具有智能的根本途径。[^1] 机器学习的损失函数是在机器学习算法中对于参数估计不可或缺的部分，而评价准则也是评判一个算法优劣性的直观示范。因此文章列举了现在在机器学习算法中最常使用的几个损失函数以及常用的评价准则。最后指出了我们接下来在评价某个算法时应该考虑的方面。

## 1 机器学习中的损失函数

### 1.1 损失函数(loss function)概念

#### 1.1.1 损失函数概述

损失函数（loss function）是用来估量你模型的预测值f(x)与真实值Y的不一致程度，它是一个非负实值函数,通常使用L(Y, f(x))来表示，损失函数越小，模型的鲁棒性就越好。损失函数是经验风险函数的核心部分，也是结构风险函数重要组成部分。模型的结构风险函数包括了经验风险项和正则项，通常可以表示成如下式子：
$$
\theta^*=\underset{\theta}{\mathrm{argmin}} {1\over N}{\displaystyle\sum_{i=1}^N L(y_i,f(x_i;\theta)+\lambda\Phi(\theta))}
$$
​	其中，前面的均值函数表示的是经验风险函数，L代表的是损失函数，后面的是正则化项或者叫惩罚项，它可以是L1，也可以是L2，或者其他的正则函数。整个式子表示的意思是找到使得目标函数最小时的值。

#### 1.1.2 损失函数和成本函数

​	从概念上来说，损失函数或成本函数指的是将一个或多个变量的事件映射到实数上的函数，该实数直观地表示与该数据相关联的一些“成本。”[^2] 但事实上，这两者还是有一些细微的差别的。损失函数我们可以理解为他是一个点上的损失，也可以认为它是整个数据集上的损失，但是成本函数指的是数据集上总的成本和损失。除此之外，成本函数还可以加上某个正则化的项。

### 1.2 常见的损失函数[^3]

#### 1.2.1 log对数损失函数(逻辑回归)

​	标准形式如下：
$$
L(Y,P(Y|X)) = -log(P(Y|X))
$$
​	在逻辑回归的推导中，它假设样本服从伯努利分布(0-1分布)，然后求得满足该分布的似然函数，接着取对数求极值等等。而逻辑回归并没有求似然函数的极值，而是把极大化当做是一种思想，进而推导出它的经验风险函数为：最小化的似然函数，即$ max F(y,f(x)) \to min -F(y,f(x))$ .从损失函数的视角来看，它就成了log损失函数了。

​	取对数是为了方便计算极大似然估计，因为在MLE中，直接求导比较困难，所以通常都是先取对数再求导找极值点。损失函数L(Y, P(Y|X))表达的是样本X在分类Y的情况下，使概率P(Y|X)达到最大值。因为log函数是单调递增的，所以log P(Y|X)也会达到最大值，因此在前面加上负号之后，最大化P(Y|X)就等价于最小化L了。

#### 1.2.2 平方损失函数(最小二乘法,Ordinary Least Squares)

​	最小二乘法是线性回归的一种，OLS将问题转化成了一个凸优化问题。在线性回归中，它假设样本和噪声都服从高斯分布(中心极限定理)最后通过极大似然估计（MLE）可以推导出最小二乘式子。最小二乘的基本原则是:最优拟合直线应该是使各点到回归直线的距离和最小的直线，即平方和最小。换言之，OLS是基于距离的，而这个距离就是我们用的最多的欧几里得距离。

​	得到平方损失函数(Square loss)的标准形式如下：
$$
L(Y,P(Y|X))  = \displaystyle\sum_{i=1}^n (Y-f(X))^2
$$
​	$Y-f(X)$表示的是残差，整个式子表示的是残差的平方和，而我们的目的就是最小化这个目标函数值，也就是最小化残差的平方和（residual sum of squares，RSS）。而在实际的应用中，我们通常会使用均方差作为衡量指标
$$
​	它只考虑误差的平均大小，不考虑其方向。但由于经过平方，与真实值偏离较多的预测值会比偏离较少的预测值受到更为严重的惩罚。再加上 MSE 的数学特性很好，这使得计算梯度变得更容易。

#### 1.2.3 绝对值损失函数

​	平均绝对误差（MAE）是另一种常用的回归损失函数，它是目标值与预测值之差绝对值的和，表示了预测值的平均误差幅度，而不需要考虑误差的方向。类似于OLS,不过它度量的是预测值和实际观测值之间绝对差之和的平均值。除此之外，它对异常值更加稳健，因为它不使用平方，也不需要使用像线性规划这样更复杂的工具来计算梯度。

平均绝对误差的标准形式如下：
$$
L(Y,P(Y|X)) = \displaystyle\sum_{i=1}^n|Y-f(X)|
$$
同样，实际应用中，我们使用的是均差
$$
MAE = {{\textstyle\sum_{i=1}^n |y_i - \bar{y_i}|} \over n}
$$

#### 1.2.4 指数损失函数(Adaboost)

​	指数损失函数的标准形式如下：
$$
L(y,f(x)) = exp(-yf(x))
$$
​	adaboost算法是前向分步加法算法的特例，是一个加和模型。损失函数就是指数函数，在Adaboost中，经过m次迭代之后，可以得到：
$$
f_m(x) = f_{m-1}(x)+\alpha_mG_m(x)
$$
Adaboost每次迭代时的目的就是为了找到是的下列式子最小化时的参数$\alpha$和G
$$
\underset{\alpha,G}{\mathrm{argmin}} = \displaystyle\sum_{i=1}^N exp[-y_i(f_{m-1}(x_i)+\alpha_mG_m(x_i))]
$$
​	可以看出，Adaboost的目标式子就是指数损失，在给定n个样本的情况下，Adaboost的损失函数为:
$$
L(y,f(x)) = {1 \over n}\displaystyle\sum_{i=1}^n exp(-yf(x_i))
$$


#### 1.2.5 Hinge 损失函数(SVM)

​	标准形式：
$$
SVMLoss = \displaystyle\sum_{j \not = y_i }max(0,s_j-s_{y_i}+1)
$$
​	在一定的安全间隔内（通常是 1），正确类别的分数应高于所有错误类别的分数之和。因此 hinge loss 常用于最大间隔分类（maximum-margin classification），最常用的是支持向量机。尽管不可微，但它是一个凸函数，因此可以轻而易举地使用机器学习领域中常用的凸优化器。

​	在线性支持向量机中，最优化的问题可以等价于下列的式子：
$$
\underset{\omega,b}{\mathrm{min}} \displaystyle\sum_i^N[1-y_i(\omega x_i + b)]_+ + \lambda||\omega||^2
$$
对式子进行变形,令：
$$
[1-y_i(\omega x_i + b)]_+=\xi_i
$$
有：
$$
\underset{\omega,b}{\mathrm{min}} \displaystyle\sum_i^N\xi_i + \lambda||\omega||^2
$$
取$\lambda = {1\over 2C}$有
$$
\underset{\omega,b}{\mathrm{min}} {1\over C}(C\displaystyle\sum_i^N\xi_i + {1\over 2}||\omega||^2)
$$
式子前部分就是hinge损失函数，而后面相当于L2正则项。

#### 1.2.6 softmax损失函数

标准形式：
$$
L(y,f(x)) = {1\over N}\displaystyle\sum_{i=1}^n exp[-y_if(x_i)]
$$
​	在神经网络中，多分类问题时常见的损失函数就是softmax，softmax作为分类任务的输出层。 简单认为softmax输出的是几个类别的概率，并且概率和为1。例如，有三个类别，经过 softmax函数后的概率输出为[0.1, 0.7, 0.2]，概率和为1，概率值最大的类别就是输入数据所对应的类别，0.7概率值最大，所以输入经过计算被分类到第二类中。
$$
\sigma(z)_j ={e^{z_j}\over \textstyle\sum_{k=1}^Ke^{z_k}}
$$

#### 1.2.7 交叉熵损失函数

$$
CrossEntropLoss = -(y_ilog(\bar {y_i}) + (1- y_i)log(1 - \bar {y_i}))
$$

​	随着预测概率偏离实际标签，交叉熵损失会逐渐增加。当实际标签为 1(y(i)=1) 时，函数的后半部分消失，而当实际标签是为 0(y(i=0)) 时，函数的前半部分消失，我们只是把对真实值类别的实际预测概率的对数相乘。交叉熵损失会重重惩罚那些置信度高但是错误的预测值。

#### 1.2.8 0-1损失函数(0-1 loss function)

​	当预测值和真实值不一样时，损失函数值为1，如预测值与真实值相等，那么损失函数值为0

### 1.3 小结

​	损失函数在机器学习中扮演着重要的角色,不同应用场景下选择不同的损失函数。以MSE和MAE为例：均方误差（MSE）是目标变量与预测值之间距离平方之和。平均绝对误差（MAE）是目标变量和预测变量之间差异绝对值之和。因此，它在一组预测中衡量误差的平均大小，而不考虑误差的方向。使用平方误差更容易求解，但使用绝对误差对离群点更加鲁棒。如果离群点是会影响业务、而且是应该被检测到的异常值，那么我们应该使用MSE。另一方面，如果我们认为离群点仅仅代表数据损坏，那么我们应该选择MAE作为损失。

​	影响损失函数选择的因素主要包括：是否有离群点，机器学习算法的选择，运行梯度下降的时间效率，是否易于找到函数的导数，以及预测结果的置信度等。

## 2 机器学习的评价标准[^4]

### 2.1 评价标准概述

​	一般的，机器学习过程包括两个阶段，分别为：原型设计阶段（Prototyping）与应用阶段（Deployed），与软件开发类似的Debug与Release阶段。

​	Prototyping阶段是使用历史数据训练一个适合解决目标任务的一个或多个机器学习模型，并对模型进行验证（Validation）与离线评估（Offline evalutation），然后通过评估指标选择一个较好的模型。如在分类任务中，选择一个适合自己问题的最好的分类算法。

​	Deployed阶段是当模型达到设定的指标值时便将模型上线，投入生产，使用新生成的数据来对该模型进行在线评估（Online evalution），以及使用新数据更新模型。

​	在对模型进行离线评估或者在线评估时，它们所用的评价指标往往不同。如在离线评估中，我们经常使用的有准确率（accuracy）、精确率－召回率（precision－recall），而在在线评估中，一般使用一些商业评价指标，如用户生命周期值（customer lifetime value）、广告点击率（click through rate）、用户流失率（customer churn rate）等，这些指标才是模型使用者最终关心的一些指标。甚至在对模型进行训练和验证过程中使用的评价指标都不一样。 

​	而在研究方面，研究重点应该在原型设计阶段，所以接下来，主要讨论一下在原型设计阶段中的评价标准。不同的机器学习任务有着不同的性能评价指标。例如，在垃圾邮件检测系统中，它本身是一个二分类问题（垃圾邮件vs正常邮件），可以使用准确率（Accuracy）、对数损失函数（log-loss）、AUC等评价方法。又如在股票预测中，它本身是一个实数序列数据预测问题，可以使用平方根误差（root mean square error， RMSE）等指标；又如在搜索引擎中进行与查询相关的项目排序中，可以使用精确率－召回率（precision-recall）、NDCG （normalized discounted cumulative gain）。 

​	在原型阶段中最重要的任务便是选择一个正确的适合的模型对数据进行拟合。而当模型训练完毕后，我们需要使用一个与训练数据集独立的新的数据集去对模型进行验证。因为模型本身就是使用训练数据集训练出来的，因此它已经对训练集进行了很好的拟合，但是它在新的数据集上的效果则有待验证，因此需要使用新的与训练集独立的数据集对模型进行训练，确保该模型在新的数据集上也能够满足要求。模型能够对新的数据也能work称为模型的泛化能力。 

### 2.2 常见评价指标

​	评价指标是机器学习任务中非常重要的一环。不同的机器学习任务有着不同的评价指标，同时同一种机器学习任务也有着不同的评价指标，每个指标的着重点不一样。如分类（classification）、回归（regression）、排序（ranking）、聚类（clustering）、热门主题模型（topic modeling）、推荐（recommendation）等。并且很多指标可以对多种不同的机器学习模型进行评价，如精确率－召回率（precision-recall），可以用在分类、推荐、排序等中。

#### 2.2.1 分类评价标准

​	分类是指对给定的数据记录预测该记录所属的类别。并且类别空间已知。它包括二分类与多分类，二分类便是指只有两种类别，如垃圾邮件分类中便是二分类问题，因为类别空间只有垃圾邮件和非垃圾邮件这两种，可以称为“负”（negative）与正（positive）两种类别，一般在实际计算中，将其映射到“0”-“1” class中；而多分类则指类别数超过两种。下面主要根据二分类的评价指标进行讲解，不过同时它们也可扩展到多分类任务中。下面对分类中一些常用的评价指标进行介绍。

##### 2.2.1.1 准确率

​	准确率是指在分类中，使用测试集对模型进行分类，分类正确的记录个数占总记录个数的比例：
$$
adduracy = {n_{correct}\over n_{total}}
$$
​	准确率看起来很简单，但是没有对不同类别进行区分。它平均地对待每一个类别。但是这个评价在某些时候并不够。比如有的时候，要看类别0与类别1下分类错误的各自个数，因为不同类别下分类错误的代价不同，即对不同类别的偏向不同，另一个原因是，可能数据分布不平衡，即有的类别下的样本过多，有的类别下的样本个数过少，两类个数相差较大。这样，样本占大部分的类别主导了准确率的计算，为了解决这个问题，对准确率进行改进，得到平均准确率。

##### 2.2.1.2 平均准确率

​	为了应对每个类别下样本的个数不一样的情况，对准确率进行变种，计算每个类别下的准确率，然后再计算它们的平均值。举例，类别0的准确率为80%，类别1下的准确率为97.5%，那么平均准确率为88.75%。因为每个类别下类别的样本个数不一样，即计算每个类别的准确率时，分母不一样，则平均准确率不等于准确率，如果每个类别下的样本个数一样，则平均准确率与准确率相等。 

​	平均准确率也有自己的缺点，比如，如果存在某个类别，类别的样本个数很少，那么使用测试集进行测试时（如k-fold cross validation），可能造成该类别准确率的方差过大，意味着该类别的准确率可靠性不强。

##### 2.2.1.3 对数损失函数

​	在分类输出中，若输出不再是0-1，而是实数值，即属于每个类别的概率，那么可以使用Log-loss对分类结果进行评价。

​	这个输出概率表示该记录所属的其对应的类别的置信度。比如如果样本本属于类别0，但是分类器则输出其属于类别1的概率为0.51，那么这种情况认为分类器出错了。该概率接近了分类器的分类的边界概率0.5。Log-loss是一个软的分类准确率度量方法，使用概率来表示其所属的类别的置信度。Log-loss具体的数学表达式为： 
$$
log_loss = -{1\over N}\displaystyle\sum_{i=1}^N y_i log p_i + (1-y_i)log(1-p_i)
$$
​	其中，$y_i$是指第i个样本所属的真实类别0或者1，$p_i$表示第i个样本属于类别1的概率，这样上式中的两个部分对于每个样本只会选择其一，因为有一个一定为0，当预测与实际类别完全匹配时，则两个部分都是0，其中假定0log0=0。

​	其实，从数学上来看，Log-loss的表达式是非常漂亮的。我们仔细观察可以发现，其信息论中的交叉熵(Cross Entropy，即真实值与预测值的交叉熵)，它与相对熵(Relative Entropy，也称为KL距离或KL散度， Kullback–Leibler divergence.)也非常像。信息熵是对事情的不确定性进行度量，不确定越大，熵越大。交叉熵包含了真实分布的熵加上假设与真实分布不同的分布的不确定性。因此，log-loss是对额外噪声(extra noise)的度量，这个噪声是由于预测值域实际值不同而产生的。因此最小化交叉熵，便是最大化分类器的准确率。 

##### 2.2.1.4 精确率-召回率

​	精确率-召回率其实是两个评价指标。但是它们一般都是同时使用。精确率是指分类器分类正确的正样本的个数占该分类器所有分类为正样本个数的比例。召回率是指分类器分类正确的正样本个数占所有的正样本个数的比例。

F1-score:

F1-score为精确率与召回率的调和平均值，它的值更接近于Precision与Recall中较小的值。即：
$$
F1 = {{2*precision * recall} \over {precision + recall}}
$$

##### 2.2.1.5 AUC，ROC

​	AUC的全称是Area under the Curve，即曲线下的面积，这条曲线便是ROC曲线，全称为the Receiver Operating Characteristic曲线。ROC曲线描述分类器的True Positive Rate（TPR，分类器分类正确的正样本个数占总正样本个数的比例）与False Positive Rate（FPR，分类器分类错误的负样本个数占总负样本个数的比例）之间的变化关系。

​	ROC曲线描述FPR不断变化时，TPR的值，即FPR与TPR之间的关系曲线。显而易见，最好的分类器便是FPR＝0%，TPR＝100%，但是一般在实践中一个分类器很难会有这么好的效果，即一般TPR不等于1，FPR不等于0的。当使用ROC曲线对分类器进行评价时，如果对多个分类器进行比较时，如果直接使用ROC曲线很难去比较，只能通过将ROC分别画出来，然后进行肉眼比较，那么这种方法是非常不便的，因此我们需要一种定量的指标去比较，这个指标便是AUC了，即ROC曲线下的面积，面积越大，分类器的效果越好，AUC的值介于0.5到1.0之间。 

​	具体如何描绘ROC曲线，如在二分类中，我们需要设定一个阈值，大于阈值分类正类，否则分为负类。因此，我们可以变化阈值，根据不同的阈值进行分类，根据分类结果计算得到ROC空间中的一些点，连接这些点就形成ROC曲线。ROC曲线会经过(0,0)与(1,1)这两点，实际上这两点的连线形成的ROC代表一个随机分类器，一般情况下分类器的ROC曲线会在这条对角连线上方。 

​	在ROC曲线中，点(0,0)表示TPR＝0，FPR＝0，即分类器将每个实例都预测为负类；点(1,1)表示TPR＝1，FPR＝1，即分类器将每个实例都预测为正类；点(0,0)表示TPR＝1，FPR=0，即分类器将每个正类实例都预测为正类，将每个负类实例都预测为负类，这是一个理想模型。 

​	ROC曲线有个很好的特性：当测试集中的正负样本的分布变化的时候，ROC曲线能够保持不变。在实际的数据集中，经常会出现类别不平衡（class imbalance）现象，即负样本比正样本少很多（或者相反），而且测试数据集中的正负样本的分布也可能随时间发生变化。

##### 2.2.1.6 混淆矩阵

​	混淆矩阵是对分类的结果进行详细描述的一个表，无论是分类正确还是错误，并且对不同的类别进行了区分，对于二分类则是一个2*2的矩阵，对于n分类则是n*n的矩阵。对于二分类，第一行是真实类别为“Positive”的记录个数（样本个数），第二行则是真实类别为“Negative”的记录个数，第一列是预测值为“Positive”的记录个数，第二列则是预测值为“Negative”的记录个数。如下表所示：

|                     | Predicted As Positive | Predicted as Negative |
| :-----------------: | :-------------------: | :-------------------: |
| Labeled as Positive |   True Positive(TP)   |  False Negative(FN)   |
| Labeled as Negative |  False Positive(FP)   |   True Negative(TN)   |

如上表，可以将结果分为四类： 
* 真正(True Positive, TP)：被模型分类正确的正样本； 
* 假负(False Negative, FN)：被模型分类错误的正样本； 
* 假正(False Positive, FP)：被模型分类的负样本； 
* 真负(True Negative, TN)：被模型分类正确的负样本；

进一步可以推出这些指标： 
* 真正率(True Positive Rate, TPR)，又名灵敏度(Sensitivity)：分类正确的正样本个数占整个正样本个数的比例，即：$TPR = {TP \over {TP + FN}}$
* 假负率(False Negative Rate, FNR)：分类错误的正样本的个数占正样本的个数的比例，即：$FNR = {FN \over {TP + FN}}$
* 假正率(False Positive Rate, FPR)：分类错误的负样本个数占整个负样本个数的比例，即：$FPR = {FP \over {FP + TN}}$
* 真负率(True Negative Rate, TNR)：分类正确的负样本的个数占负样本的个数的比例，即：$TPR = {TN \over {FP + TN}}$

再进一步，由混淆矩阵可以计算以下评价指标：

* 准确率(Accuracy)：分类正确的样本个数占所有样本个数的比例，即：
  $$
  accuracy = {{TP+TN}\over {TP+FN+FP+TN}}
  $$






- 平均准确率(Average per-class accuracy)：每个类别下的准确率的算术平均，即：
  $$
  average_accuracy={{{{TP}\over{TP+FN}}+{{TN}\over{TN+FP}}}\over 2}
  $$

- 精确率(Precision)：分类正确的正样本个数占分类器所有的正样本个数的比例，即：
  $$
  Precision = {{TP}\over {TP+FP}}
  $$

- 召回率(Recall)：分类正确的正样本个数占正样本个数的比例，即： 
  $$
  Recall = {{TP}\over{TP+FN}}
  $$

- F1-Score：精确率与召回率的调和平均值，它的值更接近于Precision与Recall中较小的值，即：
  $$
  F1 = {{2*precision*recall}\over precision + recall}
  $$

- ROC曲线 

  - x轴是FPR
  - y轴是TPR

#### 2.2.2 回归评价指标

​	与分类不同的是，回归是对连续的实数值进行预测，即输出值是连续的实数值，而分类中是离散值。例如，给你历史股票价格，公司与市场的一些信息，需要你去预测将来一段时间内股票的价格走势。那么这个任务便是回归任务。对于回归模型的评价指标主要有以下将要讨论的几种。 

##### 2.2.2.1 RMSE

​	回归模型中最常用的评价模型便是RMSE（root mean square error，平方根误差），其又被称为RMSD（root mean square deviation），其定义如下： 
$$
RMSE = \sqrt{{\textstyle\sum_{i=0}^n(y_i- \bar{y_i})^2}\over n}
$$
​	其中，$y_i$是第$i$个样本的真实值，$\bar {y_i}$是第$i$个样本的预测值，$n$是样本的个数。该评价指标使用的便是欧式距离。

​	RMSE虽然广为使用，但是其存在一些缺点，因为它是使用平均误差，而平均值对异常点（outliers）较敏感，如果回归器对某个点的回归值很不理性，那么它的误差则较大，从而会对RMSE的值有较大影响，即平均值是非鲁棒的。 

##### 2.2.2.2 Quantiles of Errors 

​	为了改进RMSE的缺点，提高评价指标的鲁棒性，使用误差的分位数来代替，如中位数来代替平均数。假设100个数，最大的数再怎么改变，中位数也不会变，因此其对异常点具有鲁棒性。

​	在现实数据中，往往会存在异常点，并且模型可能对异常点拟合得并不好，因此提高评价指标的鲁棒性至关重要，于是可以使用中位数来替代平均数，如MAPE：
$$
MAPE = {median(|y_i- \bar{y_i}|)\over y_i}
$$
​	MAPE是一个相对误差的中位数，当然也可以使用别的分位数。 

##### 2.2.2.3 Almost Correct Predictions 

​	有时我们可以使用相对误差不超过设定的值来计算平均误差，如当$(|y_i- \bar{y_i}|)\over y_i$超过100%，则认为它是一个异常点。从而剔除这个异常点，将异常点剔除之后，再计算平均误差或者中位数误差来对模型进行评价。

#### 2.2.3 排序评价指标

​	排序任务指对对象集按照与输入的相关性进行排序并返回排序结果的过程。其实，排序也可以说是一个二分类问题。即将对象池中的对象分为与查询词相关的正类与不相关的负类。并且每一个对象都有一个得分，即其属于正类的置信度，然后按照这个置信度将正类进行排序并返回。

​	对排序器进行评价的一下指标如下： 

- Precision-Recall精确率-召回率 

  精确率-召回率已经在分类器的评价指标中介绍过。它们同样也可以用于对排序器进行评价。
  $$
  precision = {{happy\enspace correct\enspace answers}\over{totla \enspace items \enspace returned \enspace by \enspace ranker}} \\
  recall = {{happy\enspace correct\enspace answers} \over {total \enspace relevant \ items}}
  $$
  ​	排序器返回top k的items，如k＝5, 10, 20, 100等。那么该评价指标改为“precision@k”和“recall@k.”

  在推荐系统中，它相当于一个多兴趣查询，即每个用户是一个查询词，然后返回每个查询词相关的top k项目，即返回每个用户感兴趣的top k项目，那么在计算评价指标值时，则需要对每个用户的精确率与召回率进行平均(average precision@k” and “average recall@k”)，将平均值作为模型的精确率与召回率。

- Precision-Recall Curve和F1 Score

  ​	当我们改变top k中的k值时，便可以得到不同的精确率与召回率，那么我们可以通过改变k值而得到精确率曲线和召回率曲线。与ROC曲线一样，我们也需要一个定量的指标对其ROC曲线进行描述而来评价其对应的模型进行评价。可取多个k值，然后计算其评价的精确率与召回率。 

  ​	除了Precision-Recall曲线外，另一个便是F1 Score，在分类器评价指标中也有提及到，它将精确度与召回率两个指标结合起来，如下：
  $$
  F1 = {{2 *precision*recall}\over precision + recall}
  $$
  F1-score是精确率与召回率的调和平均值，它的值更接近于Precision与Recall中较小的值。

- NDCG

  ​        在精确率与召回率中，返回集中每个项目的地位（权值）是一样，即位置k处的项目与位置1处的项目地位一样，但是实际情况应该是越排在前面的项目越相关，得分越高。NDCG（normalized discounted cumulative gain）指标便考虑了这种情况，在介绍NDCG之前，首先介绍一下CG(cumulative gain与DCG(discounted cumulative gain)。CG是对排序返回的top k个项目的相关性（即得分）求和，而DCG在每个项目的得分乘上一个权值，该权值与位置成反方向（如成反比），即位置越近，权值越大。而NDCG则对每项的带权值得分先进行归一化，然后再求和。 

  ​	在信息检索中或者那些对项目的返回位置关心的模型中经常使用DCG或NDCG

## 参考文献：

[^1]: 田恬.英国皇家学会发布新的调研项目——机器学习[J].科技导报,2016,34(03):93.
[^2]: [损失函数](https://en.wikipedia.org/wiki/Loss_function)
[^3]: [机器学习中的损失函数](https://blog.csdn.net/ture_dream/article/details/54948518)

[^4]: [机器学习模型评价(Evaluating Machine Learning Models)-主要概念与陷阱](https://blog.csdn.net/heyongluoyao8/article/details/49408319)